# PostgreSQL to MySQL ETL Pipeline - Orchestrated with Airflow

## Ringkasan Proyek
Sebuah ETL Pipeline (Extract, Transform, Load) yang dibangun menggunakan Apache Airflow untuk memindahkan data dari PostgreSQL (source database) ke MySQL (data warehouse) secara otomatis, terjadwal, dan incremental. Pipeline ini mensimulasikan workflow Data Engineering production-ready dengan orkestrasi berbasis container.

## ğŸ¯ Fitur Utama
- ğŸ”„ Ekstraksi Inkremental
Hanya mengambil data yang berubah dalam 24 jam terakhir
- ğŸ§¹ Transformasi Data
Pembersihan, validasi, dan standardisasi data
- âš¡ Load Optimal (Upsert)
Menggunakan INSERT ... ON DUPLICATE KEY UPDATE
- â±ï¸ Scheduling Otomatis
Pipeline berjalan setiap 6 jam
- ğŸ³ Containerized Environment
Menggunakan Docker untuk kemudahan deployment

## ğŸ—ï¸ Arsitektur Pipeline
PostgreSQL (Source)  
        â†“
   Extract Task  
        â†“
    Apache Airflow  
        â†“
Transform & Load Task  
        â†“
 MySQL (Data Warehouse)  

 ## ğŸ› ï¸ Teknologi yang Digunakan
 | Teknologi               | Versi | Fungsi                 |
| ----------------------- | ----- | ---------------------- |
| Apache Airflow          | 2.x+  | Workflow Orchestration |
| PostgreSQL              | 14+   | Source Database        |
| MySQL                   | 8.x   | Data Warehouse         |
| Docker & Docker Compose | -     | Containerization       |
| Python                  | 3.9+  | ETL Logic              |

## ğŸ“ Struktur Proyek
postgres-to-mysql-etl/  
â”œâ”€â”€ airflow/  
â”‚   â”œâ”€â”€ dags/  
â”‚   â”‚   â””â”€â”€ postgres_to_mysql_etl.py    # Main DAG file  
â”‚   â”œâ”€â”€ logs/  
â”‚   â””â”€â”€ plugins/  
â”œâ”€â”€ docker-compose.yml                  # Container configuration  
â”œâ”€â”€ requirements.txt                    # Python dependencies  
â””â”€â”€ README.md                           # Project documentation  

## ğŸ—„ï¸ Konfigurasi Database
1ï¸âƒ£ PostgreSQL (Source Database)  
Airflow Connection ID: postgres_source  
Schema: raw_data  
Source Tables:  
ğŸ”„ raw_data.customers  
ğŸ”„ raw_data.products  
ğŸ”„ raw_data.suppliers  
ğŸ”„ raw_data.orders  
Filter Ekstraksi (Incremental): updated_at >= CURRENT_DATE - INTERVAL '1 day' (sql)  

2ï¸âƒ£ MySQL (Data Warehouse)  
Airflow Connection ID: mysql_warehouse  
Target Tables:  
ğŸ”„ dim_customers (Dimensi)  
ğŸ”„ dim_products (Dimensi)  
ğŸ”„ fact_orders (Fakta)  

## ğŸ”„ Alur ETL Pipeline
1ï¸âƒ£ EXTRACT
Mengambil data dari PostgreSQL menggunakan PostgresHook:
-extract_customers() â†’ Data pelanggan  
-extract_products() â†’ Data produk  
-extract_orders() â†’ Data pesanan  
ğŸ“¦ Output:  
Data dikonversi menjadi list of dictionaries dan disimpan ke XCom  

2ï¸âƒ£ TRANSFORM  
Contoh transformasi yang diterapkan:  
ğŸ“ Format nomor telepon pelanggan  
ğŸ”  Konversi state menjadi UPPERCASE  
ğŸ’° Perhitungan margin produk  
âŒ Validasi nilai negatif pada total order  
ğŸ“… Standardisasi format tanggal  

3ï¸âƒ£ LOAD  
-Memasukkan data ke MySQL menggunakan MySqlHook:  
-INSERT ... ON DUPLICATE KEY UPDATE  
-Mendukung incremental load  
-Penanganan error & retry logic  

## â±ï¸ Scheduling  
DAG dijalankan setiap 6 jam: schedule_interval = timedelta(hours=6)  

## ğŸš€ Cara Menjalankan Proyek  
1ï¸âƒ£ Clone dan setup project  
-git clone <repository-url>  
-cd postgres-to-mysql-etl  
2ï¸âƒ£ Jalankan Docker services  
docker-compose up -d  
3ï¸âƒ£ Verifikasi container  
docker-compose ps  
4ï¸âƒ£ Akses Airflow Web UI  
ğŸŒ URL: http://localhost:8080  
ğŸ” Login:  
-Username: airflow  
-Password: airflow  
5ï¸âƒ£ Aktifkan & Trigger DAG  
-Masuk ke halaman DAGs  
-Cari DAG postgres_to_mysql_etl  
-Aktifkan DAG (toggle ON)  
Klik â–¶ï¸ Trigger DAG  
6ï¸âƒ£ Monitoring  
ğŸ“Š Pantau status task di Graph View  
ğŸ“„ Cek logs untuk troubleshooting  
âœ… Verifikasi data di database target  

## ğŸ” Verifikasi Data  
1ï¸âƒ£ PostgreSQL (Source)  
docker exec -it postgres_source psql -U postgres -d source_db  
sql:  
-SELECT * FROM raw_data.customers LIMIT 5;  
-SELECT COUNT(*) FROM raw_data.orders;  
2ï¸âƒ£ MySQL (Data Warehouse)  
docker exec -it mysql_warehouse mysql -u root -p  
sql:  
USE warehouse_db;  
-SELECT * FROM dim_customers LIMIT 5;  
-SELECT * FROM dim_products LIMIT 5;  
-SELECT * FROM fact_orders LIMIT 5;  

########################################################################

# PostgreSQL Initialization Scripts

Script inisialisasi database untuk ETL pipeline PostgreSQL-to-MySQL.

## Urutan Eksekusi:
1. `01_create_schema.sql` - Buat schema dan set hak akses
2. `02_create_customers.sql` - Buat tabel customers
3. `03_create_orders.sql` - Buat tabel orders
4. `04_create_products.sql` - Buat tabel products
5. `05_create_suppliers.sql` - Buat tabel suppliers
6. `06_insert_sample_data.sql` - Insert data contoh
7. `07_create_indexes.sql` - Buat indeks untuk optimasi

## Cara Menjalankan:
### Docker Container:
Skrip akan otomatis dijalankan saat container PostgreSQL pertama kali dibuat.

### Manual Execution:
```bash
# Masuk ke container PostgreSQL
docker exec -it postgres_container psql -U postgres -d source_db

# Jalankan skrip satu per satu
\i /docker-entrypoint-initdb.d/01_create_schema.sql
\i /docker-entrypoint-initdb.d/02_create_customers.sql
# ... dan seterusnya

####################################################################################################################

# MySQL Data Warehouse Initialization Scripts

Script inisialisasi database warehouse untuk ETL pipeline PostgreSQL-to-MySQL.

## Struktur Data Warehouse:
- **Database**: `warehouse`
- **Tabel Dimensi**:
  - `dim_customers` - Dimensi pelanggan
  - `dim_products` - Dimensi produk (dengan perhitungan margin otomatis)
- **Tabel Fakta**:
  - `fact_orders` - Fakta pesanan/transaksi

## Urutan Eksekusi:
1. `01_create_database.sql` - Buat database dan user
2. `02_create_dim_customers.sql` - Buat tabel dimensi customers
3. `03_create_dim_products.sql` - Buat tabel dimensi products
4. `04_create_fact_orders.sql` - Buat tabel fakta orders
5. `05_create_indexes.sql` - Buat indeks untuk optimasi
6. `06_create_triggers.sql` - Buat trigger untuk validasi
7. `07_insert_sample_data.sql` - Insert data contoh (opsional)

## Fitur Tambahan:
1. **Generated Column**: `margin_percentage` dihitung otomatis
2. **Triggers**: Validasi data dan auto-update timestamp
3. **Foreign Keys**: Relasi antar tabel
4. **Indexes**: Optimasi untuk query analitik
5. **Constraints**: Validasi integritas data

## Cara Menjalankan:
### Docker Container:
Skrip akan otomatis dijalankan saat container MySQL pertama kali dibuat.

### Manual Execution:
```bash
# Masuk ke container MySQL
docker exec -it mysql_container mysql -u root -p

# Atau gunakan user ETL
mysql -u etl_user -p warehouse

# Jalankan skrip
SOURCE /docker-entrypoint-initdb.d/01_create_database.sql;
SOURCE /docker-entrypoint-initdb.d/02_create_dim_customers.sql;
# ... dan seterusnya
